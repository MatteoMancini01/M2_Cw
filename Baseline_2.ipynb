{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This Jupyter Notebook contains all the codes and methodologies utilised to undertake and fulfil the instructions provided in part 2 of `main.pdf`, i.e. baseline.\n",
    "\n",
    "Our aim is to implement LLMTIME procedure, we took into account one of the files provided in this repository, [llmtime.pdf](https://github.com/MatteoMancini01/M2_Cw/blob/main/instructions/llmtime.pdf). We were provided with two Python files `qwen.py` and `lora_skeleton.py`.  We created two extra Python files, `plotting.py` and `preprocessor.py`.  All Python files are stored in the directory `src`, the table below illustrates the purposes of each Python file, in `src`:\n",
    "\n",
    "|File Name| Information|\n",
    "|---------|------------|\n",
    "|[`qwen.py`](https://github.com/MatteoMancini01/M2_Cw/blob/main/src/qwen.py)| Loads the Qwen2.5-0.5B-Instruct model and tokenizer from Hugging Face, freezes all model parameters except for the LM head bias, and prepares it for inference or fine-tuning.|\n",
    "|[`lora_skeleton.py`](https://github.com/MatteoMancini01/M2_Cw/blob/main/src/lora_skeleton.py)| Implements LoRA (Low-Rank Adaptation) by wrapping the query and value projection layers of the Qwen2.5 model with trainable LoRA layers, processes the Lotka-Volterra dataset using LLMTIME, tokenizes it, and fine-tunes the model for up to 10,000 optimizer steps using PyTorch and accelerate.â€‹|\n",
    "|[`preprocessor.py`](https://github.com/MatteoMancini01/M2_Cw/blob/main/src/preprocessor.py)| Contains the class `Preprocessor`, which gives access to all the functions required for preprocessing the dataset from `lotka_volterra_data.h5`, this includes functions that scale data, converts array to string and sting back to array, all very useful pre-requisites for preprocessing the dataset.|\n",
    "|[`plotting.py`](https://github.com/MatteoMancini01/M2_Cw/blob/main/src/plotting.py)|This file is not one of the requisites for this project. Designed for plotting. File contains a class PlotProject, which contains all the plotting functions required for the Jupyter Notebooks, this aims to keep the Notebooks tidy.|\n",
    "\n",
    "For more details about each Python files, I encourage the reader to inspect them, each function within all files, have detailed doc-stings including examples on how to use them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through out this Notebook to run codes certain packages and designed functions are required, please make sure you run the following cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Document/Term2/M2/M2_Cw/m2_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-18 19:17:57.248304: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742325477.266238   12067 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742325477.270554   12067 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-18 19:17:57.296015: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from src.preprocessor import Preprocessor\n",
    "from src.qwen import load_qwen \n",
    "from src.plotting import PlotProject\n",
    "\n",
    "\n",
    "scaling_operator = Preprocessor.scaling_operator # Set scaling_operator to function \n",
    "model, tokenizer = load_qwen() # Set model = model and tokeinzer = tokenizer\n",
    "array_to_string = Preprocessor.array_to_string # Importing array_to_string(data) to convert timeseries to string\n",
    "string_to_array = Preprocessor.string_to_array # Importing string_to_array(formatted_string) to convert strings back to arrays\n",
    "\n",
    "plot_hist_MSE = PlotProject.plot_hist_MSE # Set function designed to plot MSE histograms\n",
    "plot_hist_RMSE = PlotProject.plot_hist_RMSE # Set function designed to plot RMSE histograms\n",
    "plot_pred_vs_true = PlotProject.plot_pred_vs_true # Set function to plot predicted vs true system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This procedure takes a while to run with `model.generate()`, thus, we collected all of Qwen2.5 outcomes and the relevant metrics into the directory `saved_predictions_2b`. The reader is welcome to run the cell below for loading all the relevant metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load decoded predictions generated from Qwen2.5, npz file\n",
    "loaded = np.load(\"saved_predictions_2b/my_decoded_predictions.npz\")\n",
    "my_decoded_predictions = [loaded[key] for key in loaded]\n",
    "\n",
    "# Load MSE and RMSE for each system, these are csv files\n",
    "mse_true_predicted_loaded = pd.read_csv(\"saved_predictions_2b/mse_true_predicted.csv\")\n",
    "rmse_true_predicted_loaded = pd.read_csv(\"saved_predictions_2b/rmse_true_predicted.csv\")\n",
    "\n",
    "# Load error computed between true and predicted pairs prey and predator, npz file\n",
    "loaded_error = np.load(\"saved_predictions_2b/error_per_system.npz\")\n",
    "error_per_system_loaded = [loaded_error[key] for key in loaded_error]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
