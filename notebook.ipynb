{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open `lotka_volterra_data.h5` file on notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('lotka_volterra_data.h5', 'r') as f:\n",
    "    # Access the full dataset\n",
    "    trajectories = f['trajectories'][:]\n",
    "    time_points = f['time'][:]\n",
    "\n",
    "    # Access a single trajectory\n",
    "    system_id = 0 # First system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checikng shape of the dataset, we expect trajectories to be of size $(1000 \\times 100 \\times 2)$, and time_points of size $(100 \\times 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time points shape: (100,)\n",
      "\n",
      "Trajectory shape (pray/predator): (1000, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Time points shape:',time_points.shape)\n",
    "print('')\n",
    "print('Trajectory shape (pray/predator):',trajectories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_systems, num_time_steps, num_variables = trajectories.shape\n",
    "\n",
    "# Create a DataFrame\n",
    "df_traj = pd.DataFrame({\n",
    "    \"system_id\": np.repeat(np.arange(num_systems), num_time_steps),  # Repeats 0-999, each 100 times\n",
    "    \"time_step\": np.tile(np.arange(num_time_steps), num_systems),    # Cycles 0-99 for each system\n",
    "    \"prey\": trajectories[:, :, 0].flatten(),  # Flatten prey values\n",
    "    \"predator\": trajectories[:, :, 1].flatten()  # Flatten predator values\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>prey</th>\n",
       "      <th>predator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.949917</td>\n",
       "      <td>1.040624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740551</td>\n",
       "      <td>0.779542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.682246</td>\n",
       "      <td>0.564390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.716674</td>\n",
       "      <td>0.407644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.824511</td>\n",
       "      <td>0.300283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>999</td>\n",
       "      <td>95</td>\n",
       "      <td>0.901549</td>\n",
       "      <td>0.579420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>999</td>\n",
       "      <td>96</td>\n",
       "      <td>0.957527</td>\n",
       "      <td>0.539055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>999</td>\n",
       "      <td>97</td>\n",
       "      <td>1.036460</td>\n",
       "      <td>0.515615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>999</td>\n",
       "      <td>98</td>\n",
       "      <td>1.129212</td>\n",
       "      <td>0.510619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>1.223701</td>\n",
       "      <td>0.524988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       system_id  time_step      prey  predator\n",
       "0              0          0  0.949917  1.040624\n",
       "1              0          1  0.740551  0.779542\n",
       "2              0          2  0.682246  0.564390\n",
       "3              0          3  0.716674  0.407644\n",
       "4              0          4  0.824511  0.300283\n",
       "...          ...        ...       ...       ...\n",
       "99995        999         95  0.901549  0.579420\n",
       "99996        999         96  0.957527  0.539055\n",
       "99997        999         97  1.036460  0.515615\n",
       "99998        999         98  1.129212  0.510619\n",
       "99999        999         99  1.223701  0.524988\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traj # Visualising data in dataframe format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping prey and predator into arrays to determine the maximum value for scaling procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prey_array = df_traj['prey'].to_numpy() # Converting to numpy array\n",
    "predator_array = df_traj['predator'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Dataset `lotka_volterra_data.h5`\n",
    "\n",
    "As we will see in the `Table` presented below, in the original dataset we have laues that vary significantly. To standardize the numeric range, we are going to use [quantiles]( https://en.wikipedia.org/wiki/Quantile). A quantile is a value that divides a dataset into equal-sized intervals, indicating the data points below which a given percentage if observations fall. From the project instructions it is adviced to apply a simple scaling:\n",
    "$$\n",
    "x_t' = \\frac{x_t}{\\alpha}\n",
    "$$\n",
    "where $\\alpha$ should be chosen based on the distribution of the dataset `lotka_volterra_data.h5`.\n",
    "\n",
    "In our particular case we want most of our dataset to be in range $[0,10]$. This is coded in the [`preprocessor.py`](https://github.com/MatteoMancini01/M2_Cw/blob/main/src/preprocessor.py) file, which appropriate docstrings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `numpy.quantile()`\n",
    "\n",
    "For scaling our dataset we want to use [`numpy.quantile()`](https://numpy.org/doc/2.1/reference/generated/numpy.quantile.html). The `numpy.quantile()` function calculates the quantiles of a given NumPy array. Quantiles are cut points that devide the data into intercals with equal probability. Thus `numpy.quantile()`can be used to scale our dataset dynamically, without having to worry about choosing the appropriate value for $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import class Preprocessor from src/preprocessor.py\n",
    "from src.preprocessor import Preprocessor\n",
    "\n",
    "# Set scaling_operator to function \n",
    "scaling_operator = Preprocessor.scaling_operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling factor: 0.25283724\n"
     ]
    }
   ],
   "source": [
    "trajectories_scaled, scaling_factor = scaling_operator(trajectories, 0.9, 10)\n",
    "print('Scaling factor:', scaling_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting scaled data into `pandas.DataFrame` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_systems_scaled, num_time_steps_scaled, num_variables_scaled = trajectories_scaled.shape\n",
    "\n",
    "# Create a DataFrame\n",
    "df_traj_scaled = pd.DataFrame({\n",
    "    \"system_id\": np.repeat(np.arange(num_systems_scaled), num_time_steps_scaled),  # Repeats 0-999, each 100 times\n",
    "    \"time_step\": np.tile(np.arange(num_time_steps_scaled), num_systems_scaled),    # Cycles 0-99 for each system\n",
    "    \"prey\": trajectories_scaled[:, :, 0].flatten(),  # Flatten prey values\n",
    "    \"predator\": trajectories_scaled[:, :, 1].flatten()  # Flatten predator values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting `prey` and `predator` columns into array using [`pandas.DataFrame.to_numpy`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prey_array_scaled = df_traj_scaled['prey'].to_numpy() # Converting to numpy array\n",
    "predator_array_scaled = df_traj_scaled['predator'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function that calculates the percentage of values in an array that fall outside a given range. (This seem tedious, as we set a value for quantile in the function `scaling_operator`, e.g. $q = 0.9$, means that only $10%$ of the values will be out of our custom range. But this will be used to measure what percentage of datapoints in the original dataset is outside a specific range.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_measure(arr, min_val, max_val):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the percentage of values in an array that fall outside a given range.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    arr : array-like\n",
    "        The input numerical data.\n",
    "    min_val : float\n",
    "        The minimum acceptable value.\n",
    "    max_val : float\n",
    "        The maximum acceptable value.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The percentage of values outside the range, formatted as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count values about the max range\n",
    "    outside_count = np.sum((arr < min_val)|(arr > max_val))\n",
    "\n",
    "    # Calculating the pergentage of values outside max range\n",
    "    percentage_outside = (outside_count/arr.size)*100\n",
    "\n",
    "    return f'{percentage_outside:.2f}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting scaling information into a Table using `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = 0\n",
    "max_val = 1\n",
    "Table1 = pd.DataFrame({\n",
    "\n",
    "    'Pray': [max(prey_array), np.mean(prey_array), min(prey_array), scaling_measure(prey_array, min_val, max_val)],\n",
    "    'Pray after scaling': [max(prey_array_scaled), np.mean(prey_array_scaled), min(prey_array_scaled), scaling_measure(prey_array_scaled, min_val, max_val)],\n",
    "    'Predator': [max(predator_array), np.mean(predator_array), min(predator_array), scaling_measure(predator_array, min_val, max_val)],\n",
    "    'Predator after scaling': [max(predator_array_scaled), np.mean(predator_array_scaled), min(predator_array_scaled), scaling_measure(predator_array_scaled, min_val, max_val)],\n",
    "    \n",
    "})\n",
    "Table1.index = [\"Maximim Value\", \"Mean Value\", \"Minimum Value\", f\"Values outside the range {min_val}-{max_val}\"] # Adding index for each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the table below, we can observe, scaling was successful. The reason why we want to test how many data points are outside the range $[0,1]$, is due to the fact that a lot of data points in the original dataset (pre-scaling) are very small, many of order $10^{3}$, which may affect the tokenisation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pray</th>\n",
       "      <th>Pray after scaling</th>\n",
       "      <th>Predator</th>\n",
       "      <th>Predator after scaling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Maximim Value</th>\n",
       "      <td>13.740113</td>\n",
       "      <td>54.343708</td>\n",
       "      <td>4.76849</td>\n",
       "      <td>18.859921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Value</th>\n",
       "      <td>1.698114</td>\n",
       "      <td>6.716232</td>\n",
       "      <td>0.569606</td>\n",
       "      <td>2.252856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minimum Value</th>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values outside the range 0-1</th>\n",
       "      <td>63.11%</td>\n",
       "      <td>93.83%</td>\n",
       "      <td>12.21%</td>\n",
       "      <td>77.33%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Pray Pray after scaling  Predator  \\\n",
       "Maximim Value                 13.740113          54.343708   4.76849   \n",
       "Mean Value                     1.698114           6.716232  0.569606   \n",
       "Minimum Value                  0.002077           0.008216  0.000037   \n",
       "Values outside the range 0-1     63.11%             93.83%    12.21%   \n",
       "\n",
       "                             Predator after scaling  \n",
       "Maximim Value                             18.859921  \n",
       "Mean Value                                 2.252856  \n",
       "Minimum Value                              0.000148  \n",
       "Values outside the range 0-1                 77.33%  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the last row, we can see that we have a major improvement for both `prey` and `predator` categories, the percentage of values outside the range $[0,1]$ has increased in `prey` by ~ $30%$ and `predator` by ~ $65%$. Thus, scaling was successful. Now we can proceed with the next step, i.e. converting the scaled dataset to strings, for compatibility with [Qwen2.5]( https://github.com/QwenLM/Qwen2.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Scaled Dataset into Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Document/Term2/M2/M2_Cw/m2_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.qwen import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 13, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(\"1.23\", return_tensors=\"pt\")[\"input_ids\"].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 659, 220, 17, 220, 18]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(\"1 . 2 3\", return_tensors=\"pt\")[\"input_ids\"].tolist()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
