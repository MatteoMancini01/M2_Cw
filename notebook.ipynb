{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open `lotka_volterra_data.h5` file on notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('lotka_volterra_data.h5', 'r') as f:\n",
    "    # Access the full dataset\n",
    "    trajectories = f['trajectories'][:]\n",
    "    time_points = f['time'][:]\n",
    "\n",
    "    # Access a single trajectory\n",
    "    system_id = 0 # First system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checikng shape of the dataset, we expect trajectories to be of size $(1000 \\times 100 \\times 2)$, and time_points of size $(100 \\times 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time points shape: (100,)\n",
      "\n",
      "Trajectory shape (pray/predator): (1000, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Time points shape:',time_points.shape)\n",
    "print('')\n",
    "print('Trajectory shape (pray/predator):',trajectories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_systems, num_time_steps, num_variables = trajectories.shape\n",
    "# Create a DataFrame\n",
    "df_traj = pd.DataFrame({\n",
    "    \"system_id\": np.repeat(np.arange(num_systems), num_time_steps),  # Repeats 0-999, each 100 times\n",
    "    \"time_step\": np.repeat(time_points[np.arange(num_time_steps)], num_systems),    # Cycles 0-99 for each system\n",
    "    \"prey\": trajectories[:, :, 0].flatten(),  # Flatten prey values\n",
    "    \"predator\": trajectories[:, :, 1].flatten()  # Flatten predator values\n",
    "})\n",
    "\n",
    "# np.arange(num_systems), num_time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>prey</th>\n",
       "      <th>predator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.949917</td>\n",
       "      <td>1.040624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740551</td>\n",
       "      <td>0.779542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682246</td>\n",
       "      <td>0.564390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.716674</td>\n",
       "      <td>0.407644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.824511</td>\n",
       "      <td>0.300283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>999</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.901549</td>\n",
       "      <td>0.579420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>999</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.957527</td>\n",
       "      <td>0.539055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>999</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.036460</td>\n",
       "      <td>0.515615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>999</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.129212</td>\n",
       "      <td>0.510619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>999</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.223701</td>\n",
       "      <td>0.524988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       system_id  time_step      prey  predator\n",
       "0              0        0.0  0.949917  1.040624\n",
       "1              0        0.0  0.740551  0.779542\n",
       "2              0        0.0  0.682246  0.564390\n",
       "3              0        0.0  0.716674  0.407644\n",
       "4              0        0.0  0.824511  0.300283\n",
       "...          ...        ...       ...       ...\n",
       "99995        999      200.0  0.901549  0.579420\n",
       "99996        999      200.0  0.957527  0.539055\n",
       "99997        999      200.0  1.036460  0.515615\n",
       "99998        999      200.0  1.129212  0.510619\n",
       "99999        999      200.0  1.223701  0.524988\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traj # Visualising data in dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.080808080808081\n"
     ]
    }
   ],
   "source": [
    "time_step = df_traj['time_step'].to_numpy()\n",
    "\n",
    "print(time_step[4925])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping prey and predator into arrays to determine the maximum value for scaling procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prey_array = df_traj['prey'].to_numpy() # Converting to numpy array\n",
    "predator_array = df_traj['predator'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Dataset `lotka_volterra_data.h5`\n",
    "\n",
    "As we will see in the `Table` presented below, in the original dataset we have laues that vary significantly. To standardize the numeric range, we are going to use [quantiles]( https://en.wikipedia.org/wiki/Quantile). A quantile is a value that divides a dataset into equal-sized intervals, indicating the data points below which a given percentage if observations fall. From the project instructions it is adviced to apply a simple scaling:\n",
    "$$\n",
    "x_t' = \\frac{x_t}{\\alpha}\n",
    "$$\n",
    "where $\\alpha$ should be chosen based on the distribution of the dataset `lotka_volterra_data.h5`.\n",
    "\n",
    "In our particular case we want most of our dataset to be in range $[0,10]$. This is coded in the [`preprocessor.py`](https://github.com/MatteoMancini01/M2_Cw/blob/main/src/preprocessor.py) file, which appropriate docstrings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `numpy.quantile()`\n",
    "\n",
    "For scaling our dataset we want to use [`numpy.quantile()`](https://numpy.org/doc/2.1/reference/generated/numpy.quantile.html). The `numpy.quantile()` function calculates the quantiles of a given NumPy array. Quantiles are cut points that devide the data into intercals with equal probability. Thus `numpy.quantile()`can be used to scale our dataset dynamically, without having to worry about choosing the appropriate value for $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import class Preprocessor from src/preprocessor.py\n",
    "from src.preprocessor import Preprocessor\n",
    "\n",
    "# Set scaling_operator to function \n",
    "scaling_operator = Preprocessor.scaling_operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling factor: 0.25283724\n"
     ]
    }
   ],
   "source": [
    "trajectories_scaled, scaling_factor = scaling_operator(trajectories, 0.9, 10)\n",
    "print('Scaling factor:', scaling_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting scaled data into `pandas.DataFrame` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_systems_scaled, num_time_steps_scaled, num_variables_scaled = trajectories_scaled.shape\n",
    "\n",
    "# Create a DataFrame\n",
    "df_traj_scaled = pd.DataFrame({\n",
    "    \"system_id\": np.repeat(np.arange(num_systems_scaled), num_time_steps_scaled),  # Repeats 0-999, each 100 times\n",
    "    \"time_step\": np.tile(np.arange(num_time_steps_scaled), num_systems_scaled),    # Cycles 0-99 for each system\n",
    "    \"prey\": trajectories_scaled[:, :, 0].flatten(),  # Flatten prey values\n",
    "    \"predator\": trajectories_scaled[:, :, 1].flatten()  # Flatten predator values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting `prey` and `predator` columns into array using [`pandas.DataFrame.to_numpy`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prey_array_scaled = df_traj_scaled['prey'].to_numpy() # Converting to numpy array\n",
    "predator_array_scaled = df_traj_scaled['predator'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function that calculates the percentage of values in an array that fall outside a given range. (This seem tedious, as we set a value for quantile in the function `scaling_operator`, e.g. $q = 0.9$, means that only $10%$ of the values will be out of our custom range. But this will be used to measure what percentage of datapoints in the original dataset is outside a specific range.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_measure(arr, min_val, max_val):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the percentage of values in an array that fall outside a given range.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    arr : array-like\n",
    "        The input numerical data.\n",
    "    min_val : float\n",
    "        The minimum acceptable value.\n",
    "    max_val : float\n",
    "        The maximum acceptable value.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The percentage of values outside the range, formatted as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count values about the max range\n",
    "    outside_count = np.sum((arr < min_val)|(arr > max_val))\n",
    "\n",
    "    # Calculating the pergentage of values outside max range\n",
    "    percentage_outside = (outside_count/arr.size)*100\n",
    "\n",
    "    return f'{percentage_outside:.2f}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting scaling information into a Table using `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = 0\n",
    "max_val = 1\n",
    "Table1 = pd.DataFrame({\n",
    "\n",
    "    'Pray': [max(prey_array), np.mean(prey_array), min(prey_array), scaling_measure(prey_array, min_val, max_val)],\n",
    "    'Pray after scaling': [max(prey_array_scaled), np.mean(prey_array_scaled), min(prey_array_scaled), scaling_measure(prey_array_scaled, min_val, max_val)],\n",
    "    'Predator': [max(predator_array), np.mean(predator_array), min(predator_array), scaling_measure(predator_array, min_val, max_val)],\n",
    "    'Predator after scaling': [max(predator_array_scaled), np.mean(predator_array_scaled), min(predator_array_scaled), scaling_measure(predator_array_scaled, min_val, max_val)],\n",
    "    \n",
    "})\n",
    "Table1.index = [\"Maximim Value\", \"Mean Value\", \"Minimum Value\", f\"Values outside the range {min_val}-{max_val}\"] # Adding index for each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the table below, we can observe, scaling was successful. The reason why we want to test how many data points are outside the range $[0,1]$, is due to the fact that a lot of data points in the original dataset (pre-scaling) are very small, many of order $10^{-3}$ (and smaller order $10^{-4}$), which may affect the tokenisation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pray</th>\n",
       "      <th>Pray after scaling</th>\n",
       "      <th>Predator</th>\n",
       "      <th>Predator after scaling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Maximim Value</th>\n",
       "      <td>13.740113</td>\n",
       "      <td>54.343708</td>\n",
       "      <td>4.76849</td>\n",
       "      <td>18.859921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Value</th>\n",
       "      <td>1.698114</td>\n",
       "      <td>6.716232</td>\n",
       "      <td>0.569606</td>\n",
       "      <td>2.252856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minimum Value</th>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values outside the range 0-1</th>\n",
       "      <td>63.11%</td>\n",
       "      <td>93.83%</td>\n",
       "      <td>12.21%</td>\n",
       "      <td>77.33%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Pray Pray after scaling  Predator  \\\n",
       "Maximim Value                 13.740113          54.343708   4.76849   \n",
       "Mean Value                     1.698114           6.716232  0.569606   \n",
       "Minimum Value                  0.002077           0.008216  0.000037   \n",
       "Values outside the range 0-1     63.11%             93.83%    12.21%   \n",
       "\n",
       "                             Predator after scaling  \n",
       "Maximim Value                             18.859921  \n",
       "Mean Value                                 2.252856  \n",
       "Minimum Value                              0.000148  \n",
       "Values outside the range 0-1                 77.33%  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the last row, we can see that we have a major improvement for both `prey` and `predator` categories, the percentage of values outside the range $[0,1]$ has increased in `prey` by ~ $30\\%$ and `predator` by ~ $65\\%$. Thus, scaling was successful. Now we can proceed with the next step, i.e. converting the scaled dataset to strings, for compatibility with [Qwen2.5]( https://github.com/QwenLM/Qwen2.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Qwen2.5\n",
    "\n",
    "Below a short demonstration on how to use `load_qwen()` from `src.qwen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.qwen import load_qwen # Import load_qwen\n",
    "model, tokenizer = load_qwen() # set model = model and tokeinzer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with examples provided at the end of project instructions, see [LLMTIME Preprocessing Scheme](https://github.com/MatteoMancini01/M2_Cw/blob/main/instructions/main.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 13, 17, 18]\n",
      "\n",
      "[16, 659, 220, 17, 220, 18]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(\"1.23\", return_tensors=\"pt\")[\"input_ids\"].tolist()[0])\n",
    "print('')\n",
    "print(tokenizer(\"1 . 2 3\", return_tensors=\"pt\")[\"input_ids\"].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to tokenise $[0.25,1.50;0.27,1.47;0.31,1.42]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 13, 17, 20, 11, 16, 13, 20, 15, 26, 15, 13, 17, 22, 11, 16, 13, 19, 22, 26, 15, 13, 18, 16, 11, 16, 13, 19, 17]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(\"0.25,1.50;0.27,1.47;0.31,1.42\", return_tensors='pt')[\"input_ids\"].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how `load_qwen()` works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Hello, world' # Define input text\n",
    "input_ids = tokenizer(text, return_tensors='pt').input_ids # Tokenize text \n",
    "output = model.generate(input_ids, max_length = 50) # Generate output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above code line 3 `output`, the variable `max_length` determines how many more words will the model predict when inputing text, e.g. `text = Hello, world`, as we can see from the below output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9707,    11,  1879,     0,  1096,   374,   847,  1156,   882,  1667,\n",
       "           279,  2038,   323,   358,  1079,  4460,   311,   990,   432,   304,\n",
       "           264, 13027,  1034,    13,   576,  2038,   374,  3238,  6915,   979,\n",
       "          1598,   504,  3210,  1555,   714,   979,   358,  1430,   311,  1159,\n",
       "           432,   304,   264, 10135,  1034,   358,   633,   458,  1465,  1943]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above tensor we recognise that the first 3 tokens are related to our text, the rest of the tokens is predicted text determined from the model, as we will see below when decoding `output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world! This is my first time using the code and I am trying to use it in a Python file. The code is working fine when run from command line but when I try to import it in a python file I get an error message\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0], skip_special_tokens=True)) # Decoding output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Scaled Dataset into Strings\n",
    "\n",
    "We now have seen how tokenisation for text works! There is a small issue, Qwen2.5 is only designed to convert text, i.e. strings in Python, to tokens, while our dataset is a timeseries composed of 2 variables prey and predator over a time series of size 100, this is repated for a 1000 samples. Thus, before we proceed with tokenisation, we require to convert the time series data into sets of strings. To do so we are going to define a fucntion `array_to_string(data)`, and a function to convert string to array `sring_to_array(formatted_string)` (both functions are in [preprocessor.py](https://github.com/MatteoMancini01/M2_Cw/blob/main/src/preprocessor.py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_id</th>\n",
       "      <th>prey</th>\n",
       "      <th>predator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.757031</td>\n",
       "      <td>4.115786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.928965</td>\n",
       "      <td>3.083177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.698359</td>\n",
       "      <td>2.232228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.834528</td>\n",
       "      <td>1.612280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.261036</td>\n",
       "      <td>1.187654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>999</td>\n",
       "      <td>3.565728</td>\n",
       "      <td>2.291671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>999</td>\n",
       "      <td>3.787127</td>\n",
       "      <td>2.132025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>999</td>\n",
       "      <td>4.099317</td>\n",
       "      <td>2.039314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>999</td>\n",
       "      <td>4.466160</td>\n",
       "      <td>2.019556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>999</td>\n",
       "      <td>4.839878</td>\n",
       "      <td>2.076386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       system_id      prey  predator\n",
       "0              0  3.757031  4.115786\n",
       "1              0  2.928965  3.083177\n",
       "2              0  2.698359  2.232228\n",
       "3              0  2.834528  1.612280\n",
       "4              0  3.261036  1.187654\n",
       "...          ...       ...       ...\n",
       "99995        999  3.565728  2.291671\n",
       "99996        999  3.787127  2.132025\n",
       "99997        999  4.099317  2.039314\n",
       "99998        999  4.466160  2.019556\n",
       "99999        999  4.839878  2.076386\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_scaled=df_traj_scaled.reset_index(drop=True) # Removing Index\n",
    "traj_scaled.drop(columns=['time_step']) # Removing one of the coulmns, time_step (irrelevant for our purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessor import Preprocessor\n",
    "\n",
    "array_to_string = Preprocessor.array_to_string\n",
    "string_to_array = Preprocessor.string_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "traject_scaled_string = array_to_string(traj_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_id\n",
      "0      3.7570314,4.115786;2.9289646,3.0831769;2.69835...\n",
      "1      3.8422916,3.976525;4.266382,3.2503378;4.986718...\n",
      "2      4.2447176,4.401468;3.3779166,3.5601249;3.03805...\n",
      "3      4.1148176,4.5674887;2.6275814,4.4058175;1.7460...\n",
      "4      3.275598,3.167274;3.533418,2.2473524;4.0886607...\n",
      "                             ...                        \n",
      "995    3.918201,4.624609;2.1393397,3.2536037;1.521137...\n",
      "996    3.594898,4.6532717;2.2493894,3.7967243;1.68079...\n",
      "997    4.4646792,4.432619;4.054759,4.030011;3.8997226...\n",
      "998    4.475788,4.0170417;3.1674376,3.1674619;2.56437...\n",
      "999    4.0352407,4.488609;3.0280378,4.1001153;2.48077...\n",
      "Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(traject_scaled_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.7570314   4.115786  ]\n",
      " [ 2.9289646   3.0831769 ]\n",
      " [ 2.698359    2.232228  ]\n",
      " [ 2.834528    1.6122797 ]\n",
      " [ 3.261036    1.1876544 ]\n",
      " [ 3.9731696   0.9090103 ]\n",
      " [ 4.9950223   0.7362934 ]\n",
      " [ 6.3499713   0.6416597 ]\n",
      " [ 8.033252    0.61052966]\n",
      " [ 9.978284    0.6402782 ]\n",
      " [12.027031    0.74106705]\n",
      " [13.914932    0.9378812 ]\n",
      " [15.283247    1.2709625 ]\n",
      " [15.732348    1.7848765 ]\n",
      " [14.932756    2.4919257 ]\n",
      " [12.876417    3.2815378 ]\n",
      " [10.089222    3.8815145 ]\n",
      " [ 7.451006    4.014958  ]\n",
      " [ 5.5736156   3.6663675 ]\n",
      " [ 4.519748    3.0661838 ]\n",
      " [ 4.0797853   2.4484437 ]\n",
      " [ 4.0676417   1.9291508 ]\n",
      " [ 4.384644    1.5358958 ]\n",
      " [ 4.9906063   1.2594512 ]\n",
      " [ 5.869442    1.081379  ]\n",
      " [ 7.00247     0.98556626]\n",
      " [ 8.343905    0.9630018 ]\n",
      " [ 9.800556    1.0129801 ]\n",
      " [11.211844    1.1445497 ]\n",
      " [12.355572    1.3731911 ]\n",
      " [12.978617    1.7145051 ]\n",
      " [12.864242    2.164892  ]\n",
      " [11.940796    2.671792  ]\n",
      " [10.378936    3.1176598 ]\n",
      " [ 8.59046     3.3508794 ]\n",
      " [ 7.0140243   3.2962737 ]\n",
      " [ 5.8966465   3.0044987 ]\n",
      " [ 5.2652497   2.6000662 ]\n",
      " [ 5.044285    2.192969  ]\n",
      " [ 5.1540504   1.8450811 ]\n",
      " [ 5.5394106   1.5767686 ]\n",
      " [ 6.165034    1.3890674 ]\n",
      " [ 6.997132    1.2767583 ]\n",
      " [ 7.9853234   1.2352158 ]\n",
      " [ 9.0467615   1.2632561 ]\n",
      " [10.065218    1.3630885 ]\n",
      " [10.892034    1.539059  ]\n",
      " [11.365654    1.7920331 ]\n",
      " [11.35982     2.108443  ]\n",
      " [10.829095    2.4510555 ]\n",
      " [ 9.869668    2.750031  ]\n",
      " [ 8.698002    2.9269316 ]\n",
      " [ 7.5687656   2.9339588 ]\n",
      " [ 6.673109    2.7813456 ]\n",
      " [ 6.0946956   2.5265617 ]\n",
      " [ 5.8340306   2.23849   ]\n",
      " [ 5.855608    1.9692706 ]\n",
      " [ 6.118881    1.7475523 ]\n",
      " [ 6.585979    1.5854172 ]\n",
      " [ 7.216646    1.4846189 ]\n",
      " [ 7.9602866   1.4448124 ]\n",
      " [ 8.746588    1.4651805 ]\n",
      " [ 9.4837885   1.5457689 ]\n",
      " [10.064862    1.686082  ]\n",
      " [10.389011    1.879139  ]\n",
      " [10.378271    2.1102016 ]\n",
      " [10.015198    2.349079  ]\n",
      " [ 9.366484    2.551186  ]\n",
      " [ 8.562867    2.6719382 ]\n",
      " [ 7.7604117   2.6836882 ]\n",
      " [ 7.0902915   2.5893192 ]\n",
      " [ 6.628651    2.419172  ]\n",
      " [ 6.3997216   2.2147698 ]\n",
      " [ 6.3946714   2.013153  ]\n",
      " [ 6.5887275   1.8397428 ]\n",
      " [ 6.949876    1.7085366 ]\n",
      " [ 7.4398227   1.6256987 ]\n",
      " [ 8.010379    1.5931308 ]\n",
      " [ 8.601621    1.6109995 ]\n",
      " [ 9.140892    1.6782801 ]\n",
      " [ 9.551921    1.7912753 ]\n",
      " [ 9.765009    1.9420414 ]\n",
      " [ 9.735253    2.115139  ]\n",
      " [ 9.4618635   2.2864356 ]\n",
      " [ 8.993828    2.4261956 ]\n",
      " [ 8.418015    2.5071807 ]\n",
      " [ 7.8375545   2.5133095 ]\n",
      " [ 7.3433185   2.446743  ]\n",
      " [ 6.9946713   2.32606   ]\n",
      " [ 6.8174224   2.1781068 ]\n",
      " [ 6.8119473   2.028571  ]\n",
      " [ 6.962807    1.8969814 ]\n",
      " [ 7.244267    1.7953053 ]\n",
      " [ 7.624143    1.7310194 ]\n",
      " [ 8.060908    1.7070326 ]\n",
      " [ 8.504181    1.723896  ]\n",
      " [ 8.898368    1.7798775 ]\n",
      " [ 9.187201    1.8706486 ]\n",
      " [ 9.323835    1.987615  ]\n",
      " [ 9.283123    2.1170547 ]]\n"
     ]
    }
   ],
   "source": [
    "print(string_to_array(traject_scaled_string[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
