{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Set seed\n",
    "torch.manual_seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.qwen import load_qwen\n",
    "model_qwen, tokenizer = load_qwen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 (a) (Continued..)\n",
    "\n",
    "Plan of action:\n",
    "\n",
    "- Preprocess the data, using `load_and_preprocess`, and split the data into `train_texts`, `val_texts` and `val_text_70` $\\equiv$ 900, 100 and 100 (systems). \n",
    "- The two validation sets `val_texts` and `val_text_70` have the same `shape` but:\n",
    "    - In `val_texts` each system has the full 100 pairs of prey and predators\n",
    "    - In `val_texts_70` each system has only the first 70 pairs of prey and predators\n",
    "- We train the model on tokenised `train_texts`\n",
    "- We validated the model by predicting the remaining 30 pair points in each of the 100 system in tokenised `val_texts_70`. \n",
    "- We then compare the predicted results from `val_texts_70` to the gruond truth data `val_texts` (or `true_val_values` obtained with `data_scale_split`)\n",
    "- Just like for the untrained models we then want to compute MSE and RMSE \n",
    "- And report the loss/perplexity of each trained models\n",
    "\n",
    "We are recomended to train our model up to 10,000 steps, but we have a budgeted number of flops overall for training $10^{17}$ and due to computational power required, we are going to proceed with fewer steps first, also to familiarise with the traing procedure, before increasing the number of steps and using HPC.\n",
    "\n",
    "In synthesis:\n",
    "\n",
    "“We trained on 900 systems, validated on 100 full sequences for loss monitoring, and evaluated forecasting performance by generating future predictions given the first 70 steps from each validation sequence.”\n",
    "\n",
    "All the above description has been fully prepared in `set_up_lora.py`. For flops estimation we can use `total_transformer_training_flops` in `flops.py`. The reader is invited to explore and analyse every file in `src`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import designed functions\n",
    "from src.set_up_lora import*\n",
    "from src.flops import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model we can determine the estimate number of flops based on training steps and other metrics.\n",
    "\n",
    "For this part we do not want to exceed 5000 steps, otherwise we will be too close to the limited number of FLOPs allowed for training\n",
    "\n",
    "To train the model we are going to implement the function `train_lora_model` from `set_up_lora.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora_5000, loss_lora_5000 = train_lora_model(model_qwen, tokenizer) # default steps and hyper parameters are set here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving LoRA Weights only (Efficitent checkpoints).\n",
    "\n",
    "Save the LoRA adapter weights (not the full Qwen model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract LoRA-only weights\n",
    "lora_state_dict = {\n",
    "    name: param.cpu()\n",
    "    for name, param in model_lora_5000.named_parameters()\n",
    "    if param.requires_grad\n",
    "}\n",
    "\n",
    "#torch.save(lora_state_dict, \"trained_lora_3a_5000/lora_weight_matrices_5000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model_lora_5000.config\n",
    "\n",
    "# Parameters\n",
    "num_steps = 5000\n",
    "batch_size = 4\n",
    "seq_len = 512\n",
    "d_model = config.hidden_size\n",
    "num_heads = config.num_attention_heads\n",
    "num_layers = config.num_hidden_layers\n",
    "intermediate_dim = 2 * d_model  # SwiGLU\n",
    "lora_rank = 4  # if using LoRA\n",
    "\n",
    "total_flops_estimate = total_transformer_training_flops(num_steps, batch_size, seq_len, num_layers, d_model, num_heads, intermediate_dim, lora_rank)\n",
    "\n",
    "print(f'Total number of estimated FLOPs for training LoRA with {num_steps} steps:',total_flops_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating loss and perplexity of both tarin and validation set, there is a designed function in `set_up_lora.py`, that evaluates the perplexity and loss of the validation set, to determine the loss and perplexity of the training set, we can directly extract it from `model_lora_5000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Perplexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,val_texts, val_texts_70 = load_and_preprocess(\"data/lotka_volterra_data.h5\")\n",
    "\n",
    "max_steps = 5000 # CHANGE IF REQUIRED\n",
    "print(f\"After training with {max_steps} steps\")\n",
    "print(f\"Training loss: {loss_lora_5000:.4f}\")\n",
    "perplexity_train = np.exp(loss_lora_5000)\n",
    "print(f\"Training perplexity: {perplexity_train:.4f}\")\n",
    "\n",
    "loss_val, ppl_val = evaluate_loss_perplexity_val(model_lora_5000, tokenizer, val_texts, 4)\n",
    "print('')\n",
    "print(f'Validation loss: {loss_val:.4f}')\n",
    "print(f'Validation loss: {ppl_val:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting Missing Pair Values\n",
    "\n",
    "After training the model, we can start using its predictive ability with the function `prediction_after_training` also defined in `set_up_lora.py`. \n",
    "Our goal is to predict the missing 30 pairpoints in `val_texts_70`, to then compare it to the full validation set, already pre-defined in the function `prediction_after_training`. Once we have both sets we can evaluate the following metrics, error difference within each system, MSE and RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_encoded = prediction_after_training(model_lora_5000, tokenizer, val_texts_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Metrics\n",
    "\n",
    "To evaluate the metric mentioned above, we are going to use the designed function, `decoder_and_metrics_evaluator`, this function will return, the predicted outputs both as string-like and time=series (both outputs will be used in other functions), the true values in the validation set, and all the relevant metrics, i.e. MSE, RMSE and error in each idividual system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_decoded, predicted_output, true_values, MSE_values, RMSE_values, error_per_system = decoder_and_metrics_evaluator(predicted_encoded, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez(\"trained_lora_3a_5000/predictions_decoded_trained_lora_3a.npz\", *predictions_decoded)\n",
    "#MSE_loaded = np.save(\"trained_lora_3a_5000/MSE_values_3a.npy\", np.array(MSE_values))\n",
    "#np.save('trained_lora_3a_5000/RMSE_values_3a', RMSE_values)\n",
    "#np.savez(\"trained_lora_3a_5000/error_per_system_5000.npz\", *error_per_system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of results\n",
    "\n",
    "There is a designed function that wraps all the functions defined in `plotting.py` into a single function, `collective_plots`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collective_plots(predicted_encoded, tokenizer, system_id=0, bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter search\n",
    "\n",
    "In this section we are aiming to find the a set of hyper parameters, in particular \"rank, learning rate\" and \"context lenght\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.set_up_lora import*\n",
    "from src.preprocessor import*\n",
    "from src.flops import*\n",
    "import gc\n",
    "import torch\n",
    "from src.qwen import load_qwen\n",
    "from src.set_up_lora import*\n",
    "_, val_texts, _ = load_and_preprocess(\"data/lotka_volterra_data.h5\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy:\n",
    "\n",
    "We want to sweap through all possible combuination of the following values:\n",
    "- $r = (2,4,8)$ \"rank\"\n",
    "- $lr = (10^{-5}, 5 \\times 10^{-5}, 10^{4})$ \"learning rate\"\n",
    "- $cl = 512$ \"context length\", i.e. fixed for now\n",
    "\n",
    "The nested loop below will be very expensive in terms of computation, this will load Qwen2.5 nine times, if your local machine struggles to reload Qwen2.5 that many times, use the alternative code below.\n",
    "\n",
    "After sweaping through all possible combination, we want to use the combination that provided the smallest loss/perplexity value (both will be computed within the nested loop at each itearation). Same aplies for the next HP search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,tokenizer = load_qwen() # Load tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with r=2, lr=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  44%|████▎     | 499/1142 [02:09<02:47,  3.84it/s]\n",
      "Validating: 100%|██████████| 75/75 [00:09<00:00,  8.27it/s, avg_loss=1.1259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 1.1641\n",
      "-> Validation loss: 1.1259\n",
      "\n",
      "Training with r=2, lr=5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  44%|████▎     | 499/1142 [02:11<02:49,  3.80it/s]\n",
      "Validating: 100%|██████████| 75/75 [00:07<00:00,  9.42it/s, avg_loss=0.8970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 1.0710\n",
      "-> Validation loss: 0.8970\n",
      "\n",
      "Training with r=2, lr=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  44%|████▎     | 499/1142 [02:11<02:49,  3.79it/s]\n",
      "Validating: 100%|██████████| 75/75 [00:09<00:00,  8.12it/s, avg_loss=0.8383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 1.0383\n",
      "-> Validation loss: 0.8383\n",
      "\n",
      "Training with r=4, lr=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  44%|████▎     | 499/1142 [02:05<02:41,  3.97it/s]\n",
      "Validating: 100%|██████████| 75/75 [00:07<00:00, 10.26it/s, avg_loss=1.0203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 1.2273\n",
      "-> Validation loss: 1.0203\n",
      "\n",
      "Training with r=4, lr=5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  44%|████▎     | 499/1142 [02:06<02:42,  3.96it/s]\n",
      "Validating: 100%|██████████| 75/75 [00:09<00:00,  8.21it/s, avg_loss=0.8529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 0.8702\n",
      "-> Validation loss: 0.8529\n",
      "\n",
      "Training with r=4, lr=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  44%|████▎     | 499/1142 [02:00<02:34,  4.15it/s]\n",
      "Validating: 100%|██████████| 75/75 [00:08<00:00,  8.70it/s, avg_loss=0.7795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 0.8465\n",
      "-> Validation loss: 0.7795\n",
      "\n",
      "Training with r=8, lr=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  44%|████▎     | 499/1142 [01:59<02:33,  4.18it/s]\n",
      "Validating: 100%|██████████| 75/75 [00:07<00:00, 10.52it/s, avg_loss=0.9397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 1.0821\n",
      "-> Validation loss: 0.9397\n",
      "\n",
      "Training with r=8, lr=5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  44%|████▎     | 499/1142 [02:01<02:36,  4.12it/s]\n",
      "Validating: 100%|██████████| 75/75 [00:08<00:00,  8.79it/s, avg_loss=0.8051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 0.9173\n",
      "-> Validation loss: 0.8051\n",
      "\n",
      "Training with r=8, lr=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  44%|████▎     | 499/1142 [02:00<02:35,  4.14it/s]\n",
      "Validating: 100%|██████████| 75/75 [00:08<00:00,  8.71it/s, avg_loss=0.7376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 0.7409\n",
      "-> Validation loss: 0.7376\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_rank_lr = []\n",
    "\n",
    "ranks = [2, 4, 8]\n",
    "lrs = [1e-5, 5e-5, 1e-4]\n",
    "\n",
    "for r in ranks:\n",
    "    for lr in lrs:\n",
    "        print(f\"\\nTraining with r={r}, lr={lr}\")\n",
    "\n",
    "        # Load fresh model\n",
    "        model, _ = load_qwen()\n",
    "\n",
    "        # Train model and compute loss/perplexity\n",
    "        trained_model, final_loss = train_lora_model(model, tokenizer, lora_rank=r, learning_rate=lr, train_steps=500)\n",
    "        ppl_train = np.exp(final_loss)\n",
    "\n",
    "        # Compute validation loss and perplexity\n",
    "        val_loss, _ = evaluate_loss_perplexity_val(trained_model, tokenizer, val_texts, 4)\n",
    "        ppl_val = np.exp(val_loss)\n",
    "        \n",
    "        # Extracting config information to determine estimate number of flops\n",
    "        config = trained_model.config\n",
    "        d_model = config.hidden_size\n",
    "        num_heads = config.num_attention_heads\n",
    "        num_layers = config.num_hidden_layers\n",
    "        intermediate_dim = 2 * d_model  # SwiGLU\n",
    "\n",
    "        # Compute total estimate of flops\n",
    "        total_flops_estimate = total_transformer_training_flops(500, 4, 512, num_layers, d_model, num_heads, intermediate_dim, lora_rank=r)\n",
    "\n",
    "        # Collecting results\n",
    "        results_rank_lr.append({\"rank\": r, \"learning_rate\": lr, \"Train Loss\": final_loss, \"Train Perplexity\": ppl_train,\n",
    "                                \"Validation Loss\": val_loss, \"Validation Perplexity\":ppl_val,\"Estimated Flops\": total_flops_estimate})\n",
    "        print(f\"-> Train Loss: {final_loss:.4f}, Perplexity: {ppl_train:.2f}\")\n",
    "        print(f\"-> Validation Loss: {val_loss:.4f}, Perplexity: {ppl_val:.2f}\")\n",
    "        print(f\"-> Estimated Flops: {total_flops_estimate}\")\n",
    "\n",
    "        # Clean up to free GPU memory\n",
    "        del model\n",
    "        del trained_model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank  learning_rate  Train Loss  Validation Loss\n",
      "0     2        0.00001    1.164133         1.125851\n",
      "1     2        0.00005    1.071049         0.897050\n",
      "2     2        0.00010    1.038254         0.838324\n",
      "3     4        0.00001    1.227332         1.020328\n",
      "4     4        0.00005    0.870162         0.852907\n",
      "5     4        0.00010    0.846522         0.779493\n",
      "6     8        0.00001    1.082127         0.939741\n",
      "7     8        0.00005    0.917339         0.805061\n",
      "8     8        0.00010    0.740861         0.737563\n"
     ]
    }
   ],
   "source": [
    "# Saving results as a csv file\n",
    "HP_search_rlr_df = pd.DataFrame(results_rank_lr)\n",
    "print(HP_search_rlr_df)\n",
    "HP_search_rlr_df.to_csv(\"hp_tuning_results/hp_tun_rank_lr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After determining best hyper parameters for \"rank\" and \"learning rate\", we can procede to determine which of the three context lengths $[128, 512, 768]$ perform the best for a maximun of 2000 RLPPP steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with context_lenghts = 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  11%|█▏        | 499/4374 [04:57<38:28,  1.68it/s]\n",
      "Validating: 100%|██████████| 75/75 [01:09<00:00,  1.08it/s, avg_loss=0.7417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 0.9144\n",
      "-> Validation loss: 0.7417\n",
      "\n",
      "Training with context_lenghts = 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  44%|████▎     | 499/1142 [40:34<52:16,  4.88s/it]  \n",
      "Validating: 100%|██████████| 75/75 [00:36<00:00,  2.05it/s, avg_loss=0.7457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train loss: 0.8086\n",
      "-> Validation loss: 0.7457\n",
      "\n",
      "Training with context_lenghts = 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:   6%|▌         | 53/900 [08:15<2:12:01,  9.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Load fresh model\u001b[39;00m\n\u001b[32m     10\u001b[39m model, _ = load_qwen()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m trained_model, final_loss = \u001b[43mtrain_lora_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_rank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ctx_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m val_loss, _ = evaluate_loss_perplexity_val(trained_model, tokenizer, val_texts, \u001b[32m4\u001b[39m)\n\u001b[32m     15\u001b[39m results.append({\u001b[33m\"\u001b[39m\u001b[33mcontext_lengths\u001b[39m\u001b[33m\"\u001b[39m: cl, \u001b[33m\"\u001b[39m\u001b[33mTrain Loss\u001b[39m\u001b[33m\"\u001b[39m: final_loss, \u001b[33m\"\u001b[39m\u001b[33mValidation Loss\u001b[39m\u001b[33m\"\u001b[39m: val_loss})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/M2_Cw/src/set_up_lora.py:255\u001b[39m, in \u001b[36mtrain_lora_model\u001b[39m\u001b[34m(model, tokenizer, lora_rank, learning_rate, batch_size, max_ctx_length, train_steps)\u001b[39m\n\u001b[32m    253\u001b[39m outputs = model(batch, labels=batch)\n\u001b[32m    254\u001b[39m loss = outputs.loss\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m final_loss = \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[38;5;66;03m# Backpropagation using Accelerator\u001b[39;00m\n\u001b[32m    258\u001b[39m accelerator.backward(loss)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results_cl = []\n",
    "context_lengths = [128, 512, 768]\n",
    "best_r = 8\n",
    "best_lr = 1e-4\n",
    "\n",
    "for cl in context_lengths:\n",
    "    print(f\"\\nTraining with context_lenghts = {cl}\")\n",
    "\n",
    "    # Load fresh model\n",
    "    model, _ = load_qwen()\n",
    "    # Train the model and compute loss\n",
    "    trained_model, final_loss = train_lora_model(model, tokenizer, lora_rank=best_r, learning_rate=best_lr, max_ctx_length=cl, train_steps=500)\n",
    "    ppl_train = np.exp(final_loss)\n",
    "\n",
    "\n",
    "    # Computing validation loss and perplexity\n",
    "    val_loss, _ = evaluate_loss_perplexity_val(trained_model, tokenizer, val_texts, 4, max_length=cl)\n",
    "    ppl_val = np.exp(val_loss)\n",
    "    \n",
    "    # Extracting config info from the model to estimate flops\n",
    "    config = trained_model.config\n",
    "    d_model = config.hidden_size\n",
    "    num_heads = config.num_attention_heads\n",
    "    num_layers = config.num_hidden_layers\n",
    "    intermediate_dim = 2 * d_model  # SwiGLU\n",
    "\n",
    "    #  Computing total estimate of flops\n",
    "    total_flops_estimate = total_transformer_training_flops(500, 4, cl, num_layers, d_model, num_heads, intermediate_dim, lora_rank=best_r)\n",
    "\n",
    "    # Collecting results\n",
    "    results_cl.append({\"context_lengths\": cl, \"Train Loss\": final_loss, \"Train Perplexity\": ppl_train,\n",
    "                       \"Validation Loss\": val_loss, \"Validation Perplexity\": ppl_val,\"Estimated Flops\": total_flops_estimate})\n",
    "    \n",
    "    # Print results at each stage\n",
    "    print(f\"-> Train Loss: {final_loss:.4f}, Perplexity: {ppl_train:.2f}\")\n",
    "    print(f\"-> Validation Loss: {val_loss:.4f}, Perplexity: {ppl_val:.2f}\")\n",
    "    print(f\"-> Estimated Flops: {total_flops_estimate}\")\n",
    "\n",
    "    # Clean up to free GPU memory\n",
    "    del model\n",
    "    del trained_model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rank  learning_rate  Train Loss  Validation Loss  context_lengths\n",
      "0    2.0        0.00001    1.164133         1.125851              NaN\n",
      "1    2.0        0.00005    1.071049         0.897050              NaN\n",
      "2    2.0        0.00010    1.038254         0.838324              NaN\n",
      "3    4.0        0.00001    1.227332         1.020328              NaN\n",
      "4    4.0        0.00005    0.870162         0.852907              NaN\n",
      "5    4.0        0.00010    0.846522         0.779493              NaN\n",
      "6    8.0        0.00001    1.082127         0.939741              NaN\n",
      "7    8.0        0.00005    0.917339         0.805061              NaN\n",
      "8    8.0        0.00010    0.740861         0.737563              NaN\n",
      "9    NaN            NaN    1.050353         0.738644           0.0001\n",
      "10   NaN            NaN    0.779086         0.754333           0.0001\n",
      "11   NaN            NaN    0.904416         0.778757           0.0001\n"
     ]
    }
   ],
   "source": [
    "# Saving results as a csv file\n",
    "HP_search_cl_df = pd.DataFrame(results_cl)\n",
    "print(HP_search_cl_df)\n",
    "\n",
    "HP_search_cl_df.to_csv(\"hp_tuning_results/hp_tun_cl.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will pefrom full training and validation using the best hyper-parameters determined in the previus section, determine the number of flops and all the metrics just like in previus parts, and compare resuts of the tuned model to the trained but not tuned Qwen2.5 with LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follecting from previus results\n",
    "\n",
    "r_opt = 8 # Optimal Rank\n",
    "lr_opt = 1e-4 # optimal Learning Rate\n",
    "cl_opt = 512 # Optimal Context Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model with the above parameters (and determine loss/perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt, tokenizer = load_qwen() # Loading Qwen2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt_train, loss_best_train = train_lora_model(model, tokenizer, lora_rank=r_opt, learning_rate=lr_opt, batch_size=4, max_ctx_length=cl_opt,train_steps=5000) # Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting train and validation loss/perplexity and FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing validation loss and perplexity\n",
    "\n",
    "_, val_texts, _ = load_and_preprocess(\"data/lotka_volterra_data.h5\") # Reloading validation set\n",
    "\n",
    "ppl_best_train = np.exp(loss_best_train) # Perplexity on trained model\n",
    "\n",
    "# Validation loss and perplexity of best model\n",
    "loss_best_val, ppl_best_val = evaluate_loss_perplexity_val(model_opt_train, tokenizer, val_texts, 4,  max_length=cl_opt)\n",
    "\n",
    "# Extracting config info from the model to estimate flops\n",
    "config = model_opt_train.config\n",
    "d_model = config.hidden_size\n",
    "num_heads = config.num_attention_heads\n",
    "num_layers = config.num_hidden_layers\n",
    "intermediate_dim = 2*d_model  # SwiGLU\n",
    "\n",
    "#  Computing total estimate of flops\n",
    "total_flops_for_best_model = total_transformer_training_flops(5000, 4, cl_opt, num_layers, d_model, num_heads, intermediate_dim, lora_rank=r_opt)\n",
    "\n",
    "# collecting results\n",
    "collecting_results = {\"Training Loss\": loss_best_train, \"Training Perplexity\": ppl_best_train, \n",
    "                      \"Validation Loss\": loss_best_val, \"Validation Perplexity\": ppl_best_val,\n",
    "                      \"FLOPs\": total_flops_for_best_model}\n",
    "\n",
    "# Collecting results in pd.DataFrame\n",
    "\n",
    "best_model_results_df = pd.DataFrame(collecting_results)\n",
    "print(\"Metric results from best model:\")\n",
    "print(\"\")\n",
    "print(best_model_results_df)\n",
    "\n",
    "# Save results\n",
    "\n",
    "best_model_results_df.to_csv(\"best_model_results/best_model_trval_loss_ppl.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using best model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction after training\n",
    "_,_,val_texts_70 = load_and_preprocess(\"data/lotka_volterra_data.h5\") # Reload 70% of validation set\n",
    "\n",
    "# Compute prediction\n",
    "predicted_encoded_best = prediction_after_training(model_opt_train, tokenizer, val_texts_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining metrics from predictions, MSE, RMSE and error in each system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_decoded_best, predicted_output_best, true_values, MSE_values_best, RMSE_values_best, error_per_system_best = decoder_and_metrics_evaluator(predicted_encoded_best, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"best_model_results/predictions_decoded_best.npz\", *predictions_decoded_best)\n",
    "MSE_loaded = np.save(\"best_model_results/MSE_values_best.npy\", np.array(MSE_values_best))\n",
    "np.save('best_model_results/RMSE_values_best', RMSE_values_best)\n",
    "np.savez(\"best_model_results/error_per_system_best.npz\", *error_per_system_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collective_plots(predicted_encoded_best, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
