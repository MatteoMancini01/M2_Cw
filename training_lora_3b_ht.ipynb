{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "from src.qwen import load_qwen\n",
    "model_qwen, tokenizer = load_qwen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.set_up_lora import*\n",
    "from src.preprocessor import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Parameters that we want to search for:\n",
    "- $r = (2,4,8)$ \"rank\"\n",
    "- $lr = (10^{-5}, 5 \\times 10^{-5}, 10^{4})$ \"learning rate\"\n",
    "\n",
    "The nested loop below will be very expensive in terms of computation, this will load Qwen2.5 nine times, if your local machine struggles to reload Qwen2.5 that many times, use the alternative code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "ranks = [2, 4, 8]\n",
    "lrs = [1e-5, 5e-5, 1e-4]\n",
    "\n",
    "for r in ranks:\n",
    "    for lr in lrs:\n",
    "        print(f\"Training with r={r}, lr={lr}\")\n",
    "        model, tokenizer = load_qwen()\n",
    "        trained_model, final_loss = train_lora_model(model, tokenizer, lora_rank=r, learning_rate=lr, train_steps=500)\n",
    "        results.append({\"rank\": r, \"learning_rate\": lr, \"final_loss\": final_loss})\n",
    "        print(f\"-> final loss: {final_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "HP_search_results_df = pd.DataFrame(results)\n",
    "print(HP_search_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative (Use only if the code above keeps crashing the kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from src.qwen import load_qwen\n",
    "from src.set_up_lora import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,tokenizer = load_qwen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_texts, _ = load_and_preprocess(\"data/lotka_volterra_data.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with r=2, lr=1e-05\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "\n",
    "ranks = [2, 4, 8]\n",
    "lrs = [1e-5, 5e-5, 1e-4]\n",
    "\n",
    "for r in ranks:\n",
    "    for lr in lrs:\n",
    "        print(f\"\\nTraining with r={r}, lr={lr}\")\n",
    "\n",
    "        # Load fresh model\n",
    "        model, _ = load_qwen()\n",
    "        trained_model, final_loss = train_lora_model(model, tokenizer, lora_rank=r, learning_rate=lr, train_steps=500)\n",
    "\n",
    "        val_loss, _ = evaluate_loss_perplexity_val(trained_model, tokenizer, val_texts, 4)\n",
    "\n",
    "        results.append({\"rank\": r, \"learning_rate\": lr, \"Train Loss\": final_loss, \"Validation Loss\": val_loss})\n",
    "        print(f\"-> Train loss: {final_loss:.4f}\")\n",
    "        print(f\"-> Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Clean up to free GPU memory\n",
    "        del model\n",
    "        del trained_model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "HP_search_results_df = pd.DataFrame(results)\n",
    "print(HP_search_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After determining best hyper parameters for \"rank\" and \"learning rate\", we can procede to determine which of the three context lengths $[128, 512, 768]$ perform the best for a maximun of 2000 RLPPP steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_r = 4\n",
    "best_lr = 5e-5\n",
    "train_steps = 500  # or whatever RLPPP is\n",
    "\n",
    "context_lengths = [128, 512, 768]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1, context lengths = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = load_qwen()\n",
    "trained_model, final_loss = train_lora_model(model, tokenizer, lora_rank=r, learning_rate=lr, max_ctx_length=128, train_steps=1000)\n",
    "loss_val, _ = evaluate_loss_perplexity_val(trained_model, tokenizer, val_texts, 4)\n",
    "print(f\"-> Train loss: {final_loss:.4f}\")\n",
    "print(f\"-> Validation loss: {loss_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1, context lengths = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = load_qwen()\n",
    "trained_model, final_loss = train_lora_model(model, tokenizer, lora_rank=r, learning_rate=lr, train_steps=1000) # Default max_ctx_length=512\n",
    "loss_val, _ = evaluate_loss_perplexity_val(trained_model, tokenizer, val_texts, 4)\n",
    "print(f\"-> Train loss: {final_loss:.4f}\")\n",
    "print(f\"-> Validation loss: {loss_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1, context lengths = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = load_qwen()\n",
    "trained_model, final_loss = train_lora_model(model, tokenizer, lora_rank=r, learning_rate=lr, max_ctx_length=127688, train_steps=1000)\n",
    "loss_val, _ = evaluate_loss_perplexity_val(trained_model, tokenizer, val_texts, 4)\n",
    "print(f\"-> Train loss: {final_loss:.4f}\")\n",
    "print(f\"-> Validation loss: {loss_val:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
